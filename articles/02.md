# How nginx Tells Time Without Asking

> Deep in nginx's source code, there's a trick that lets millions of requests read the current time without ever waiting for each other. It involves 64 pre-allocated slots, a memory barrier, and a bet that your thread won't sleep for a full minute.

---

## Every Response Needs a Timestamp

Every HTTP response nginx sends includes a `Date` header:

<!-- üñºÔ∏è INSERT IMAGE: code-http-header.png (or use code block below) -->

```
HTTP/1.1 200 OK
Date: Tue, 09 Dec 2025 14:30:00 GMT
Content-Type: text/html
```

That timestamp gets written to logs too. And checked against caches. A single request might need the current time three or four times.

nginx handles millions of requests per second. That's millions of "what time is it?" questions. Every. Single. Second.

---

## Why Asking the OS for Time is Expensive

The obvious approach: call `gettimeofday()` and ask the operating system.

But here's the thing‚Äî`gettimeofday()` is a **syscall**. And syscalls are expensive:

1. Your program stops running
2. The CPU switches from "user mode" to "kernel mode"
3. The OS reads the hardware clock
4. The OS does some math
5. The CPU switches back to "user mode"
6. Your program resumes

Each syscall costs somewhere between 100 and 1000 nanoseconds. That sounds tiny. But at 10 million requests per second, with 3-4 time checks per request? You're burning 3-4 seconds of CPU time every second just asking what time it is.

<!-- üñºÔ∏è INSERT IMAGE: visual-syscall.png -->

_(Fun fact: Linux actually tries to help here. It exposes certain syscalls like `gettimeofday` through something called **vDSO** (virtual Dynamic Shared Object)‚Äîa small shared library mapped into every process that lets you read the kernel's cached time without a full context switch. But even vDSO has overhead, and nginx wanted something faster still.)_

**Okay, so cache it.** Store the time in a variable, update it once per second. Problem solved, right?

Not quite. Because now you have a new problem.

---

## The Concurrency Problem

Let's say you cache the time in a global variable. One thread updates it every second. Millions of readers access it constantly.

What happens when a reader is halfway through copying the time value, and the writer updates it?

```
Writer: time = "14:30:00"
                ‚Üì writer starts changing to "14:30:01"
Reader:         ‚Üì reader copies "14:" so far
Writer: time = "14:30:01"
Reader:         ‚Üì reader copies "30:01"
Result: Reader got "14:30:01" ‚Äî actually fine this time
```

In practice, most code paths just read a single value like `sec` or grab a pre-formatted string‚Äîboth of which are effectively atomic on modern hardware. But the _possibility_ of tearing exists, and defensive code can't assume how readers will evolve.

**The traditional fix: locks.**

```c
lock();
time_t now = cached_time;
unlock();
```

Now the reader waits for the writer to finish. And the writer waits for readers to finish. And readers wait for each other.

At millions of requests per second, that waiting adds up. You've just created a bottleneck.

---

## nginx's Solution: 64 Rotating Slots

Here's the insight that makes nginx's approach work: **don't update the slot readers are using‚Äîwrite to a different slot, then point readers there.**

From `src/core/ngx_times.c`:

<!-- üñºÔ∏è INSERT IMAGE: code-slots-def.png (or use code block below) -->

```c
#define NGX_TIME_SLOTS   64

static ngx_time_t  cached_time[NGX_TIME_SLOTS];
static u_char      cached_http_time[NGX_TIME_SLOTS]
                       [sizeof("Mon, 28 Sep 1970 06:00:00 GMT")];
```

nginx pre-allocates **64 copies** of everything:

- 64 time structures
- 64 pre-formatted HTTP date strings
- 64 pre-formatted log date strings

There's a pointer that tells readers which slot is "current":

<!-- üñºÔ∏è INSERT IMAGE: code-volatile-ptr.png (or use code block below) -->

```c
volatile ngx_time_t *ngx_cached_time;
```

### How the Writer Updates

```
Slot:    [0] [1] [2] [3] ... [63]
          ^
          |
     ngx_cached_time points here
     (readers are using this)
```

1. Writer moves to the next slot (slot 0 ‚Üí slot 1)
2. Writer fills in slot 1 with the new time data
3. Writer issues a **memory barrier** (more on this in a moment)
4. Writer swaps the pointer to slot 1

```
Slot:    [0] [1] [2] [3] ... [63]
              ^
              |
     ngx_cached_time now points here
     (new readers use this)
```

The key: **readers never see a half-written slot.** By the time the pointer changes, the new slot is completely filled in.

<!-- üñºÔ∏è INSERT IMAGE: visual-slots.png -->

### How Readers Read

<!-- üñºÔ∏è INSERT IMAGE: code-reader.png (or use code block below) -->

```c
time_t now = ngx_cached_time->sec;
```

That's it. No lock. No waiting. Just dereference the pointer and grab the value.

---

## Why 64 Slots?

Here's the only way this can go wrong:

1. A reader starts copying from slot 0
2. The reader gets preempted (OS pauses it to run something else)
3. The writer cycles through ALL 64 slots and comes back to slot 0
4. The writer starts overwriting slot 0
5. The reader wakes up and finishes copying‚Äîbut now the data is corrupted

The comment in the source code says:

> "thread may get corrupted values only if it is preempted while copying and then it is not scheduled to run more than NGX_TIME_SLOTS seconds"

But here's the nuance: nginx doesn't _always_ update once per second. Depending on configuration‚Äîsub-second timers, millisecond caches for logging‚Äîupdates can happen more frequently. The real safety property is:

```
# slots ‚â• update rate √ó worst-case thread stall time
```

64 is a practical heuristic that works for typical configurations. If your thread sleeps long enough to wrap around the entire slot ring, a corrupted timestamp is the least of your problems.

<!-- üñºÔ∏è INSERT IMAGE: visual-why64.png -->

---

## The Memory Barrier: The Crucial Detail

Look at the writer's last two operations:

```c
cached_time[1].sec = 1733749800;   // write the time data
ngx_cached_time = &cached_time[1]; // swap the pointer
```

You'd assume these run top-to-bottom. But compilers are sneaky.

Modern compilers reorder instructions aggressively to optimize performance. The compiler looks at these two lines and thinks: "These write to different memory addresses. I can reorder them!" It might emit assembly that swaps the pointer before the time data is fully written.

_(On architectures with weak memory ordering like ARM, the CPU itself can also reorder stores to different addresses. But on x86, store‚Üístore ordering is guaranteed by the hardware‚Äîthe compiler is the real threat.)_

**The disaster scenario:**

1. Compiler reorders the pointer swap before the data write
2. A reader sees the new pointer, starts reading from slot 1
3. But the time data hasn't been written to slot 1 yet
4. Reader gets garbage

**The fix:**

<!-- üñºÔ∏è INSERT IMAGE: code-barrier.png (or use code block below) -->

```c
cached_time[1].sec = 1733749800;
ngx_memory_barrier();              // STOP. Finish everything above first.
ngx_cached_time = &cached_time[1];
```

The memory barrier tells the compiler: "Don't reorder instructions across this line."

On x86, this compiles to:

<!-- üñºÔ∏è INSERT IMAGE: code-asm.png (or use code block below) -->

```c
__asm__ volatile ("" ::: "memory")
```

This is a **compiler barrier**‚Äîit generates no actual CPU instructions. It's just a note to the compiler saying "flush any cached values in registers and don't reorder memory operations across this point."

That's enough for x86, where the CPU already guarantees store ordering. On ARM or other weakly-ordered architectures, nginx uses platform-specific macros that emit real hardware fence instructions (like `dmb` or `dsb`). The portable `ngx_memory_barrier()` macro expands to whatever's needed for the target architecture.

<!-- üñºÔ∏è INSERT IMAGE: visual-barrier.png -->

---

## Why This Matters Beyond nginx

This pattern‚Äî**write to a shadow copy, then atomically swap a pointer**‚Äîshows up everywhere in high-performance systems:

- **Database page buffers**: Write to a new page, then swap pointers
- **Game engine double-buffering**: Render to a back buffer, then swap
- **Lock-free queues**: Producers and consumers operate on different ends

nginx's time cache is a textbook example of the pattern in production code that runs on roughly a third of all websites.

<!-- üñºÔ∏è INSERT IMAGE: visual-pattern.png -->

---

## One More Thing

While poking around this file, I found another gem. nginx implements its own `ngx_gmtime()` function to convert timestamps to dates. Why? Because the standard library's `localtime()` function isn't safe to call from signal handlers.

The comment explains:

> "localtime() and localtime_r() are not Async-Signal-Safe functions, therefore, they must not be called by a signal handler, so we use the cached GMT offset value. Fortunately the value is changed only two times a year."

That last line made me smile. "Fortunately the value is changed only two times a year"‚Äîreferring to daylight saving time. They're caching the timezone offset and trusting that it won't matter if it's briefly wrong during DST transitions.

<!-- üñºÔ∏è INSERT IMAGE: visual-dst.png -->

Practical engineering at its finest.

<!-- üñºÔ∏è INSERT IMAGE: visual-lessons.png -->

---

_What's the most clever concurrency trick you've seen in a codebase? I'd love to hear about it._

---

## Metadata

**Hashtags:** #nginx #concurrency #systems #programming #performance #lockfree

**Reading time:** ~6 minutes

**Source:** [nginx source code - src/core/ngx_times.c](https://github.com/nginx/nginx/blob/master/src/core/ngx_times.c)

---

## üñºÔ∏è Available Visuals (export from 02.html)

| Visual ID        | Description                                         | Use After                            |
| ---------------- | --------------------------------------------------- | ------------------------------------ |
| `visual-syscall` | Syscall cost breakdown (user/kernel mode switches)  | "Why Asking the OS for Time" section |
| `visual-slots`   | 64 rotating slots diagram (before/after)            | "nginx's Solution" section           |
| `visual-why64`   | Why 64 slots is enough (failure mode)               | "Why 64 Slots?" section              |
| `visual-barrier` | Memory barrier problem (with/without comparison)    | "The Memory Barrier" section         |
| `visual-pattern` | Where this pattern appears (databases, games, etc.) | "Why This Matters" section           |
| `visual-dst`     | The DST comment from the source code                | "One More Thing" section             |
| `visual-lessons` | Key takeaways                                       | End of article                       |

### Code Snippets (styled)

| Code ID             | Description                          | Replaces                      |
| ------------------- | ------------------------------------ | ----------------------------- |
| `code-slots-def`    | NGX_TIME_SLOTS and array definitions | First code block in Solution  |
| `code-volatile-ptr` | The volatile pointer declaration     | Second code block in Solution |
| `code-reader`       | Lock-free reader code                | "How Readers Read" code block |
| `code-barrier`      | Memory barrier in context            | Memory barrier section code   |
| `code-asm`          | x86 asm volatile definition          | `__asm__` code block          |
| `code-http-header`  | HTTP response with Date header       | Opening HTTP example          |
